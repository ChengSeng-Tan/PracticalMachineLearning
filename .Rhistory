trainRaw <- read.csv("./data/pml-training.csv")
testRaw <- read.csv("./data/pml-testing.csv")
dim(trainRaw)
dim(testRaw)
sum(complete.cases(trainRaw))
sum(complete.cases(testRaw))
str(trainRaw)
str(testRaw)
NZV <- nearZeroVar(trainRaw, saveMetrics = TRUE)
head(NZV, 20)
dat = read.csv("./data/pml-training.csv", na.strings=c("", "NA"))
str(dat)
dat <- dat[, colSums(is.na(dat)) == 0]
str(dat)
dat = dat[8:length(dat)]
str(dat)
dat$classe<-as.factor(dat$classe)
inTrain = createDataPartition(dat$classe, p = 3/4)[[1]]
training = dat[ inTrain,]
validation = dat[-inTrain,]
library(caret)
set.seed(100)
inTrain <- createDataPartition(data$classe, p=0.7, list=FALSE)
inTrain <- createDataPartition(dat$classe, p=0.7, list=FALSE)
training <- dat[inTrain,]
validation <- dat[-inTrain,]
# plot a correlation matrix
correlMatrix <- cor(training[, -length(training)])
corrplot(correlMatrix, type = "lower", tl.cex = 0.8)
library(corrplot)
install.packages("corrplat")
install.packages("corrplot")
library(corrplot)
# plot a correlation matrix
correlMatrix <- cor(training[, -length(training)])
corrplot(correlMatrix, type = "lower", tl.cex = 0.8)
corrplot(cor(training[, -length(names(training))]), method = "color", tl.cex = 0.8)
corrplot(cor(training[, -length(names(training))]), type = "lower", method = "color", tl.cex = 0.8)
corrplot(cor(training[, -length(names(training))]), type = "lower", tl.cex = 0.8)
rf <- train(classe ~ ., data = training, method = "rf", trControl = trainControl(method = "cv", 5), ntree = 250)
getTree(rf$finalModel, k=2)
rfres = predict(rf,validation)
confusionMatrix(validation$classe, rfres)
testing = read.csv("./data/pml-testing.csv", na.strings=c("", "NA"))
testing <- testing[, colSums(is.na(testing)) == 0]
# remove unimportant columns in 1st seven columns
testing = testing[8:length(dat2)]
testing = testing[8:length(testing)]
names(testing)
testing = read.csv("./data/pml-testing.csv", na.strings=c("", "NA"))
testing <- testing[, colSums(is.na(testing)) == 0]
names(testing)
testing = testing[8:length(testing)]
predict(rf,testing)
accuracy = confusionMatrix(validation$classe, rfres)$overall['Accuracy']
(1 - accuracy) * 100
pred = predict(rf,validation)
#Get an estimate of how well the model has been trained;
confusionMatrix(validation$classe, pred)
acc= confusionMatrix(validation$classe, pred)$overall['Accuracy']
ose = (1 - accuracy) * 100
print(round(ose, digits = 2))
testing = read.csv("./data/pml-testing.csv", na.strings=c("", "NA"))
testing <- testing[, colSums(is.na(testing)) == 0]
# remove unimportant columns in 1st seven columns
testing = testing[8:length(testing)]
setwd("~/GitHub/PracticalMachineLearning")
rf
pred = predict(rf,validation)
confusionMatrix(validation$classe, pred)
acc= postResample(pred, validation$classe)
ose = (1 - accuracy) * 100
print(round(ose, digits = 2))
postResample(pred, validation$classe)
postResample(pred, validation$classe)[1]
acc <- postResample(pred, validation$classe)[1]
print(round(acc, digits = 2))
ose = (1 - acc) * 100
print(round(ose, digits = 2))
acc <- postResample(pred, validation$classe)[1]
print(round(acc, digits = 4))
ose = (1 - acc) * 100
print("Out of sample error");print(round(ose, digits = 2))
acc <- postResample(pred, validation$classe)[1]
print(round(acc, digits = 4))
ose = (1 - acc) * 100
print("Out of sample error",round(ose, digits = 2))
acc <- postResample(pred, validation$classe)[1]
print(round(acc, digits = 4))
ose = (1 - acc) * 100
print(c("Out of sample error: ",round(ose, digits = 2))
)
acc <- postResample(pred, validation$classe)[1]
print(round(acc, digits = 4))
ose = (1 - acc) * 100
print(c('Out of sample error: ',round(ose, digits = 2)))
acc <- postResample(pred, validation$classe)[1]
print(round(acc, digits = 4))
ose <- (1 - acc) * 100
print(round(ose, digits = 2))
class(ose)
dim(ose)
names(ose)
knit_with_parameters('~/GitHub/PracticalMachineLearning/Project Writeup.Rmd')
